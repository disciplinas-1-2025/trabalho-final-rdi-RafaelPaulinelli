# Trabalho Final - RecuperaÃ§Ã£o da InformaÃ§Ã£o (2025/2)

Este repositÃ³rio contÃ©m a anÃ¡lise comparativa entre dados reais de mercado (State of Data Brazil) e vagas coletadas via Web Scraping.

## ğŸ“‚ Estrutura do Projeto
- `src/coleta`: Scripts utilizados para baixar dados do Kaggle e raspar vagas do Python.org.
- `src/limpeza`: Scripts de tratamento e padronizaÃ§Ã£o dos textos.
- `data/`: ContÃ©m os datasets brutos (raw) e processados.
- `docs/`: RelatÃ³rio final em PDF gerado a partir da anÃ¡lise.
- `notebooks/`: Jupyter Notebook com o cÃ³digo do Modelo de RecuperaÃ§Ã£o (TF-IDF) e visualizaÃ§Ãµes.

## ğŸš€ Como Executar
1. O projeto requer as bibliotecas listadas (pandas, sklearn, matplotlib, seaborn).
2. Para visualizar a anÃ¡lise completa, acesse o arquivo `Relatorio_Final.pdf` na pasta `docs` (ou `data/raw`).
3. O cÃ³digo fonte principal estÃ¡ no notebook `notebooks/Relatorio_Final.ipynb`.

## ğŸ“Š Resumo
Foi aplicado um modelo vetorial (TF-IDF) para recuperar vagas relevantes baseadas em termos de busca, comparando o perfil das vagas com o perfil dos profissionais do Data Hackers.
